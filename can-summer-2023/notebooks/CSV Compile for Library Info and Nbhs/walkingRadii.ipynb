{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "310a3d32-d5fe-432e-af4c-f34bc4ca1d41",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "720ea06a-9084-419c-b80e-59782555d2c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "#from rajvi_mapbox_api import MapboxAPI\n",
    "import requests\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "from shapely.geometry import shape, Polygon\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('default')\n",
    "import geopandas as gpd\n",
    "import geodatasets\n",
    "import ast\n",
    "from shapely import wkt\n",
    "from pyproj import Geod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2adde6e-3ae1-4334-add4-cf5aef59c52f",
   "metadata": {},
   "source": [
    "## Importing Coverage Function (allows me to pick any branch I want)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd3fb992-9787-4002-9055-5feeb8f2d11b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#reading in library branch and population demographics, both with geometry data\n",
    "#branchInfo = pd.read_csv('../library neighborhoods/completedNeighborhoodRadiiDF.csv')\n",
    "branchInfo5 = pd.read_csv('../library neighborhoods/5branchRadii.csv')\n",
    "branchInfo7 = pd.read_csv('../library neighborhoods/7minus5branchRadii.csv')\n",
    "branchInfo9 = pd.read_csv('../library neighborhoods/9minus7branchRadii.csv')\n",
    "branchInfo11 = pd.read_csv('../library neighborhoods/11minus9branchRadii.csv')\n",
    "branchInfo13 = pd.read_csv('../library neighborhoods/13minus11branchRadii.csv')\n",
    "branchInfo15 = pd.read_csv('../library neighborhoods/15minus13branchRadii.csv')\n",
    "branchInfo17 = pd.read_csv('../library neighborhoods/17minus15branchRadii.csv')\n",
    "branchInfo19 = pd.read_csv('../library neighborhoods/19minus17branchRadii.csv')\n",
    "branchInfo21 = pd.read_csv('../library neighborhoods/21minus19branchRadii.csv')\n",
    "branchInfo23 = pd.read_csv('../library neighborhoods/23minus21branchRadii.csv')\n",
    "branchInfo25 = pd.read_csv('../library neighborhoods/25minus23branchRadii.csv')\n",
    "branchInfo27 = pd.read_csv('../library neighborhoods/27minus25branchRadii.csv')\n",
    "branchInfo29 = pd.read_csv('../library neighborhoods/29minus27branchRadii.csv')\n",
    "censusTracts = pd.read_csv('../../data/clean/population_demographics.csv')\n",
    "censusDemographics = pd.read_csv('../../data/final_data/census_demos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f03cb1d-61ea-4c6d-9c1a-718267695dbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#removing unecessary columns from branchInfo\n",
    "#removing unecessary columns from censusTracts\n",
    "censusTracts = censusTracts[['geoid','geometry','qualifying name']]\n",
    "#converting censusTracts to a geodataframe (we could not load it as one since it already had a geometry column so we are simply\n",
    "#converting the geometry column to a proper gpd geometry column).\n",
    "censusTracts = gpd.GeoDataFrame(\n",
    "    censusTracts.loc[:, [c for c in censusTracts.columns if c != \"geometry\"]],\n",
    "    geometry=gpd.GeoSeries.from_wkt(censusTracts[\"geometry\"]),\n",
    "    crs=\"epsg:4326\",\n",
    "    )\n",
    "#branchInfo[['LATITUDE', 'LONGITUDE']] = [ast.literal_eval(x)[:2] for x in branchInfo['LOCATION']]\n",
    "#branchInfo.loc[:, 'LATITUDE'] = pd.to_numeric(branchInfo.loc[:, 'LATITUDE'])\n",
    "#branchInfo.loc[:, 'LONGITUDE'] = pd.to_numeric(branchInfo.loc[:, 'LONGITUDE'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d67ce808-9a9e-4f94-8c21-988706775f7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "censusPops = censusDemographics[['geoid', 'total population', 'Percent Workers 16+: Car, Truck, or Van ']].copy(deep=True)\n",
    "censusPops['Transportation: Car, Truck, or Van'] = censusPops['total population']*censusPops['Percent Workers 16+: Car, Truck, or Van ']\n",
    "censusPops = censusPops.drop(columns = ['total population', 'Percent Workers 16+: Car, Truck, or Van '])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "250e0fdb-ecbc-463e-8f66-9ae571b40df9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "branchInfo5 = branchInfo5.drop(columns = ['Unnamed: 0'])\n",
    "branchInfo5 = gpd.GeoDataFrame(\n",
    "    branchInfo5.loc[:, [c for c in branchInfo5.columns if c != \"geometry\"]],\n",
    "    geometry=gpd.GeoSeries.from_wkt(branchInfo5[\"geometry\"]),\n",
    "    crs=\"epsg:4326\",\n",
    "    )\n",
    "    \n",
    "branchInfo7 = branchInfo7.drop(columns = ['Unnamed: 0'])\n",
    "branchInfo7 = gpd.GeoDataFrame(\n",
    "    branchInfo7.loc[:, [c for c in branchInfo7.columns if c != \"geometry\"]],\n",
    "    geometry=gpd.GeoSeries.from_wkt(branchInfo7[\"geometry\"]),\n",
    "    crs=\"epsg:4326\",\n",
    "    )\n",
    "\n",
    "branchInfo9 = branchInfo9.drop(columns = ['Unnamed: 0'])\n",
    "branchInfo9 = gpd.GeoDataFrame(\n",
    "    branchInfo9.loc[:, [c for c in branchInfo9.columns if c != \"geometry\"]],\n",
    "    geometry=gpd.GeoSeries.from_wkt(branchInfo9[\"geometry\"]),\n",
    "    crs=\"epsg:4326\",\n",
    "    )\n",
    "\n",
    "branchInfo11 = branchInfo11.drop(columns = ['Unnamed: 0'])\n",
    "branchInfo11 = gpd.GeoDataFrame(\n",
    "    branchInfo11.loc[:, [c for c in branchInfo11.columns if c != \"geometry\"]],\n",
    "    geometry=gpd.GeoSeries.from_wkt(branchInfo11[\"geometry\"]),\n",
    "    crs=\"epsg:4326\",\n",
    "    )\n",
    "\n",
    "branchInfo13 = branchInfo13.drop(columns = ['Unnamed: 0'])\n",
    "branchInfo13 = gpd.GeoDataFrame(\n",
    "    branchInfo13.loc[:, [c for c in branchInfo13.columns if c != \"geometry\"]],\n",
    "    geometry=gpd.GeoSeries.from_wkt(branchInfo13[\"geometry\"]),\n",
    "    crs=\"epsg:4326\",\n",
    "    )\n",
    "\n",
    "branchInfo15 = branchInfo15.drop(columns = ['Unnamed: 0'])\n",
    "branchInfo15 = gpd.GeoDataFrame(\n",
    "    branchInfo15.loc[:, [c for c in branchInfo15.columns if c != \"geometry\"]],\n",
    "    geometry=gpd.GeoSeries.from_wkt(branchInfo15[\"geometry\"]),\n",
    "    crs=\"epsg:4326\",\n",
    "    )\n",
    "\n",
    "branchInfo17 = branchInfo17.drop(columns = ['Unnamed: 0'])\n",
    "branchInfo17 = gpd.GeoDataFrame(\n",
    "    branchInfo17.loc[:, [c for c in branchInfo17.columns if c != \"geometry\"]],\n",
    "    geometry=gpd.GeoSeries.from_wkt(branchInfo17[\"geometry\"]),\n",
    "    crs=\"epsg:4326\",\n",
    "    )\n",
    "\n",
    "branchInfo19 = branchInfo19.drop(columns = ['Unnamed: 0'])\n",
    "branchInfo19 = gpd.GeoDataFrame(\n",
    "    branchInfo19.loc[:, [c for c in branchInfo19.columns if c != \"geometry\"]],\n",
    "    geometry=gpd.GeoSeries.from_wkt(branchInfo19[\"geometry\"]),\n",
    "    crs=\"epsg:4326\",\n",
    "    )\n",
    "\n",
    "branchInfo21 = branchInfo21.drop(columns = ['Unnamed: 0'])\n",
    "branchInfo21 = gpd.GeoDataFrame(\n",
    "    branchInfo21.loc[:, [c for c in branchInfo21.columns if c != \"geometry\"]],\n",
    "    geometry=gpd.GeoSeries.from_wkt(branchInfo21[\"geometry\"]),\n",
    "    crs=\"epsg:4326\",\n",
    "    )\n",
    "\n",
    "branchInfo23 = branchInfo23.drop(columns = ['Unnamed: 0'])\n",
    "branchInfo23 = gpd.GeoDataFrame(\n",
    "    branchInfo23.loc[:, [c for c in branchInfo23.columns if c != \"geometry\"]],\n",
    "    geometry=gpd.GeoSeries.from_wkt(branchInfo23[\"geometry\"]),\n",
    "    crs=\"epsg:4326\",\n",
    "    )\n",
    "\n",
    "branchInfo25 = branchInfo25.drop(columns = ['Unnamed: 0'])\n",
    "branchInfo25 = gpd.GeoDataFrame(\n",
    "    branchInfo25.loc[:, [c for c in branchInfo25.columns if c != \"geometry\"]],\n",
    "    geometry=gpd.GeoSeries.from_wkt(branchInfo25[\"geometry\"]),\n",
    "    crs=\"epsg:4326\",\n",
    "    )\n",
    "\n",
    "branchInfo27 = branchInfo27.drop(columns = ['Unnamed: 0'])\n",
    "branchInfo27 = gpd.GeoDataFrame(\n",
    "    branchInfo27.loc[:, [c for c in branchInfo27.columns if c != \"geometry\"]],\n",
    "    geometry=gpd.GeoSeries.from_wkt(branchInfo27[\"geometry\"]),\n",
    "    crs=\"epsg:4326\",\n",
    "    )\n",
    "\n",
    "branchInfo29 = branchInfo29.drop(columns = ['Unnamed: 0'])\n",
    "branchInfo29 = gpd.GeoDataFrame(\n",
    "    branchInfo29.loc[:, [c for c in branchInfo29.columns if c != \"geometry\"]],\n",
    "    geometry=gpd.GeoSeries.from_wkt(branchInfo29[\"geometry\"]),\n",
    "    crs=\"epsg:4326\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9b283a9-38ab-48bb-a77a-d4aa7e54df1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#helper method to ensure that two polygons overlap before getting the intersection. Gets the intersection then calculates\n",
    "#the percent of overlapping area for a census tract and saves it to a dictionary with the census tract geo-id as the key and\n",
    "#the percent as the value.\n",
    "def check(polygon1, df, geoname, dictionary,key):\n",
    "   \n",
    "    for i in range(len(df)):\n",
    "        if polygon1.intersects(df.loc[i,geoname]): \n",
    "            overlapPolygon = (polygon1.intersection(df.loc[i,geoname]))\n",
    "            poly_area, poly_perimeter = geod.geometry_area_perimeter(overlapPolygon)\n",
    "            overlapArea = poly_area*-1\n",
    "            propOverlap = overlapArea / df.loc[i,'Area']\n",
    "            #print(propOverlap)\n",
    "            dictionary[df.loc[i, key]] = propOverlap\n",
    "    return dictionary\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f55d16a5-21aa-4815-903d-f5c49e368473",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#sets the crs of gpd types\n",
    "def geoSetup(gdf):\n",
    "    \n",
    "    gdf = gdf.set_crs('EPSG:4326')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14c92e58-ebe5-444c-9131-73307d1ccc8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#cdf = gdf of geometry area which you want to get the coverage score\n",
    "#idf = gdf of points for which you want to get an isochrone and dictionary of percent of overlap in cdf areas\n",
    "#scoreString = a string that is the name of the coverage score column you choose\n",
    "#dictString = a string that is the name of the dictionary column you choose\n",
    "#cgs = a string that is the name of the geometry column in the cdf\n",
    "#igs = a string that is the name of the geometry column in the idf\n",
    "#lat = a string that is the name of the latitude column in the idf\n",
    "#lon = a string that is the name of the longitude column in the idf\n",
    "#key = a string that is the name of the column in the cdf that you want to represent the key of the dictionary\n",
    "\n",
    "def appendADS(cdf,idf,scoreString,dictString,cgs,igs,key):\n",
    "    \n",
    "    #api = MapboxAPI()\n",
    "    cdf[scoreString] = 0.0\n",
    "    idf[dictString] = ''\n",
    "    censusAreas = []\n",
    "    global geod \n",
    "    geod = Geod(ellps='WGS84')\n",
    "   \n",
    "    geoSetup(cdf)\n",
    "    geoSetup(idf)\n",
    "   \n",
    "    for index, row in cdf.iterrows():\n",
    "        poly_area, poly_perimeter = geod.geometry_area_perimeter(row[cgs])\n",
    "        poly_area = poly_area*-1\n",
    "        censusAreas.append(poly_area)\n",
    "    \n",
    "    cdf['Area'] = censusAreas\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(len(idf)):\n",
    "        dictionary = {}\n",
    "        dictionary = check(idf.loc[i,igs],cdf,cgs, dictionary,key)\n",
    "        idf.loc[i,dictString]= [dictionary]\n",
    "    \n",
    "        for i in range(len(cdf)):\n",
    "   \n",
    "            if dictionary.get(cdf.loc[i, key]) != None:\n",
    "                score = cdf.loc[i, scoreString]\n",
    "                cdf.loc[i, scoreString] = score + dictionary.get(cdf.loc[i, key])\n",
    "  \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "653b7b55-9a25-4fa6-8f12-981051b128da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.9/site-packages/shapely/predicates.py:798: RuntimeWarning: invalid value encountered in intersects\n",
      "  return lib.intersects(a, b, **kwargs)\n",
      "/opt/tljh/user/lib/python3.9/site-packages/shapely/predicates.py:798: RuntimeWarning: invalid value encountered in intersects\n",
      "  return lib.intersects(a, b, **kwargs)\n",
      "/opt/tljh/user/lib/python3.9/site-packages/shapely/predicates.py:798: RuntimeWarning: invalid value encountered in intersects\n",
      "  return lib.intersects(a, b, **kwargs)\n",
      "/opt/tljh/user/lib/python3.9/site-packages/shapely/predicates.py:798: RuntimeWarning: invalid value encountered in intersects\n",
      "  return lib.intersects(a, b, **kwargs)\n",
      "/opt/tljh/user/lib/python3.9/site-packages/shapely/predicates.py:798: RuntimeWarning: invalid value encountered in intersects\n",
      "  return lib.intersects(a, b, **kwargs)\n",
      "/opt/tljh/user/lib/python3.9/site-packages/shapely/predicates.py:798: RuntimeWarning: invalid value encountered in intersects\n",
      "  return lib.intersects(a, b, **kwargs)\n",
      "/opt/tljh/user/lib/python3.9/site-packages/shapely/predicates.py:798: RuntimeWarning: invalid value encountered in intersects\n",
      "  return lib.intersects(a, b, **kwargs)\n",
      "/opt/tljh/user/lib/python3.9/site-packages/shapely/predicates.py:798: RuntimeWarning: invalid value encountered in intersects\n",
      "  return lib.intersects(a, b, **kwargs)\n",
      "/opt/tljh/user/lib/python3.9/site-packages/shapely/predicates.py:798: RuntimeWarning: invalid value encountered in intersects\n",
      "  return lib.intersects(a, b, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "appendADS(censusTracts,branchInfo5, 'score', 'list of dict','geometry','geometry','geoid')\n",
    "appendADS(censusTracts,branchInfo7, 'score', 'list of dict','geometry','geometry','geoid')\n",
    "appendADS(censusTracts,branchInfo9, 'score', 'list of dict','geometry','geometry','geoid')\n",
    "appendADS(censusTracts,branchInfo11, 'score', 'list of dict','geometry','geometry','geoid')\n",
    "appendADS(censusTracts,branchInfo13, 'score', 'list of dict','geometry','geometry','geoid')\n",
    "appendADS(censusTracts,branchInfo15, 'score', 'list of dict','geometry','geometry','geoid')\n",
    "appendADS(censusTracts,branchInfo17, 'score', 'list of dict','geometry','geometry','geoid')\n",
    "appendADS(censusTracts,branchInfo19, 'score', 'list of dict','geometry','geometry','geoid')\n",
    "appendADS(censusTracts,branchInfo21, 'score', 'list of dict','geometry','geometry','geoid')\n",
    "appendADS(censusTracts,branchInfo23, 'score', 'list of dict','geometry','geometry','geoid')\n",
    "appendADS(censusTracts,branchInfo25, 'score', 'list of dict','geometry','geometry','geoid')\n",
    "appendADS(censusTracts,branchInfo27, 'score', 'list of dict','geometry','geometry','geoid')\n",
    "appendADS(censusTracts,branchInfo29, 'score', 'list of dict','geometry','geometry','geoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20abda80-82bc-4277-9850-4dcf01460886",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BRANCH</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>geometry</th>\n",
       "      <th>list of dict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albany Park</td>\n",
       "      <td>(41.97557881655979, -87.71361314512697)</td>\n",
       "      <td>41.975579</td>\n",
       "      <td>-87.713613</td>\n",
       "      <td>POLYGON ((-87.71361 41.97980, -87.71561 41.978...</td>\n",
       "      <td>[{17031140200: 0.024261414648178242, 170318318...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Altgeld</td>\n",
       "      <td>(41.65719847558056, -87.59883829075173)</td>\n",
       "      <td>41.657198</td>\n",
       "      <td>-87.598838</td>\n",
       "      <td>POLYGON ((-87.59884 41.65834, -87.60070 41.658...</td>\n",
       "      <td>[{17031540101: 0.03491984488141061, 1703154010...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Archer Heights</td>\n",
       "      <td>(41.80110836194246, -87.72648385568911)</td>\n",
       "      <td>41.801108</td>\n",
       "      <td>-87.726484</td>\n",
       "      <td>POLYGON ((-87.72448 41.80420, -87.72548 41.804...</td>\n",
       "      <td>[{17031620200: 0.02353879749607556, 1703157050...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           BRANCH                                 LOCATION   LATITUDE  \\\n",
       "0     Albany Park  (41.97557881655979, -87.71361314512697)  41.975579   \n",
       "1         Altgeld  (41.65719847558056, -87.59883829075173)  41.657198   \n",
       "2  Archer Heights  (41.80110836194246, -87.72648385568911)  41.801108   \n",
       "\n",
       "   LONGITUDE                                           geometry  \\\n",
       "0 -87.713613  POLYGON ((-87.71361 41.97980, -87.71561 41.978...   \n",
       "1 -87.598838  POLYGON ((-87.59884 41.65834, -87.60070 41.658...   \n",
       "2 -87.726484  POLYGON ((-87.72448 41.80420, -87.72548 41.804...   \n",
       "\n",
       "                                        list of dict  \n",
       "0  [{17031140200: 0.024261414648178242, 170318318...  \n",
       "1  [{17031540101: 0.03491984488141061, 1703154010...  \n",
       "2  [{17031620200: 0.02353879749607556, 1703157050...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "branchInfo5.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46474b4-1bec-45ce-86d2-1c56d8021cf6",
   "metadata": {},
   "source": [
    "## Average Travel Time Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9d77c83e-c44c-4839-b759-5cf44a101b02",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#Internet\n",
    "def min5Radius(DemographicsVariables, branchWithCensus):\n",
    "    pop_in_branch = (branchWithCensus['Percent Overlap']  * branchWithCensus['total population']).sum()\n",
    "    #Branch_pop_withInternet = (branchWithCensus['Percent Overlap'] * branchWithCensus[DemographicsVariables] * branchWithCensus['Total']).sum() \n",
    "    #result = Branch_pop_withInternet/pop_in_branch\n",
    "    return pop_in_branch   \n",
    "\n",
    "#Income\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e3f30ed9-2877-4c13-902f-258bfc5b8440",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def branch_demographics(branchWithCensus, nameOfBranch):\n",
    "    branch_snapshot_df = pd.DataFrame({'Branch': [nameOfBranch]})\n",
    "    list1 = ['5 Min']\n",
    "    for i in list1:\n",
    "        branch_snapshot_df[i] = min5Radius(i, branchWithCensus)\n",
    "    \n",
    "    return branch_snapshot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19ce4a83-f838-49e6-b5f0-454d934e94d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def incrementPopulations(branchDataset):\n",
    "    popPerLib = pd.DataFrame(columns=['Branch', 'Given Min Pop'])\n",
    "\n",
    "    for i in range(len(branchDataset)):\n",
    "        \n",
    "        #Locating only Altgeld's column 'list of dict'\n",
    "        libraryDictList = branchDataset.loc[i,'list of dict']\n",
    "        branchName = branchDataset.loc[i,'BRANCH']\n",
    "        \n",
    "        #Removed set of brackets, just a dictionary now\n",
    "        finalDictionary = libraryDictList[0]\n",
    "\n",
    "        #Seperating into two columns\n",
    "        dictToList = pd.DataFrame(finalDictionary.items(), columns= ['geoid','Percent Overlap'])\n",
    "        libraryAndCensus = censusPops.merge(dictToList, on='geoid')\n",
    "\n",
    "        libraryAndCensus['counts'] = 0\n",
    "        for j in range(len(libraryAndCensus)):\n",
    "            libraryAndCensus.loc[j,'counts'] = libraryAndCensus.loc[j,'Transportation: Car, Truck, or Van'] * libraryAndCensus.loc[j,'Percent Overlap']\n",
    "        \n",
    "        libPop = pd.DataFrame({'BRANCH': [branchName],'Given Min Pop': libraryAndCensus['counts'].sum()})\n",
    "        popPerLib = pd.concat([popPerLib, libPop])\n",
    "        \n",
    "    popPerLib = popPerLib.drop(columns = ['Branch'])\n",
    "    popPerLib = popPerLib.reset_index()\n",
    "    popPerLib = popPerLib.drop(columns = ['index'])\n",
    "    \n",
    "    return popPerLib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfda1bbf-0d05-440a-bce7-eb73ca070993",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "c5Min0Population = incrementPopulations(branchInfo5)\n",
    "c7Min5Population = incrementPopulations(branchInfo7)\n",
    "c9Min7Population = incrementPopulations(branchInfo9)\n",
    "c11Min9Population = incrementPopulations(branchInfo11)\n",
    "c13Min11Population = incrementPopulations(branchInfo13)\n",
    "c15Min13Population = incrementPopulations(branchInfo15)\n",
    "c17Min15Population = incrementPopulations(branchInfo17)\n",
    "c19Min17Population = incrementPopulations(branchInfo19)\n",
    "c21Min19Population = incrementPopulations(branchInfo21)\n",
    "c23Min21Population = incrementPopulations(branchInfo23)\n",
    "c25Min23Population = incrementPopulations(branchInfo25)\n",
    "c27Min25Population = incrementPopulations(branchInfo27)\n",
    "c29Min27Population = incrementPopulations(branchInfo29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c793a34-775c-4686-a926-78e8c46a5fde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "allRadiiPops = pd.DataFrame(columns=['Branch', 'Prop 0 to 5 Min', 'Prop 5 to 7 Min', 'Prop 7 to 9 Min', 'Prop 9 to 11 Min', \n",
    "                                     'Prop 11 to 13 Min', 'Prop 13 to 15 Min', 'Prop 15 to 17 Min', 'Prop 17 to 19 Min',\n",
    "                                     'Prop 19 to 21 Min', 'Prop 21 to 23 Min', 'Prop 23 to 25 Min', 'Prop 25 to 27 Min', \n",
    "                                     'Prop 27 to 29 Min', 'Total Pop Around Library'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66a06e48-7641-4310-a8ab-d10b8db729dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "allRadiiPops['Branch'] = c5Min0Population['BRANCH']\n",
    "allRadiiPops['Prop 0 to 5 Min'] = c5Min0Population['Given Min Pop']\n",
    "allRadiiPops['Prop 5 to 7 Min'] = c7Min5Population['Given Min Pop']\n",
    "allRadiiPops['Prop 7 to 9 Min'] = c9Min7Population['Given Min Pop']\n",
    "allRadiiPops['Prop 9 to 11 Min'] = c11Min9Population['Given Min Pop']\n",
    "allRadiiPops['Prop 11 to 13 Min'] = c13Min11Population['Given Min Pop']\n",
    "allRadiiPops['Prop 13 to 15 Min'] = c15Min13Population['Given Min Pop']\n",
    "allRadiiPops['Prop 15 to 17 Min'] = c17Min15Population['Given Min Pop']\n",
    "allRadiiPops['Prop 17 to 19 Min'] = c19Min17Population['Given Min Pop']\n",
    "allRadiiPops['Prop 19 to 21 Min'] = c21Min19Population['Given Min Pop']\n",
    "allRadiiPops['Prop 21 to 23 Min'] = c23Min21Population['Given Min Pop']\n",
    "allRadiiPops['Prop 23 to 25 Min'] = c25Min23Population['Given Min Pop']\n",
    "allRadiiPops['Prop 25 to 27 Min'] = c27Min25Population['Given Min Pop']\n",
    "allRadiiPops['Prop 27 to 29 Min'] = c29Min27Population['Given Min Pop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16d8abb5-26fb-46de-ba36-f9356121bb84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "allRadiiPops = allRadiiPops.fillna(0)\n",
    "allRadiiPops = allRadiiPops.set_index('Branch')\n",
    "allRadiiPops['Total Pop Around Library'] = allRadiiPops.sum(axis=1)\n",
    "allRadiiPops.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9630f3c2-5c53-4bc7-ac4d-e24837a3c504",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "allRadiiPops['Prop 0 to 5 Min'] = allRadiiPops['Prop 0 to 5 Min']/allRadiiPops['Total Pop Around Library']\n",
    "allRadiiPops['Prop 5 to 7 Min'] = allRadiiPops['Prop 5 to 7 Min']/allRadiiPops['Total Pop Around Library']\n",
    "allRadiiPops['Prop 7 to 9 Min'] = allRadiiPops['Prop 7 to 9 Min']/allRadiiPops['Total Pop Around Library']\n",
    "allRadiiPops['Prop 9 to 11 Min'] = allRadiiPops['Prop 9 to 11 Min']/allRadiiPops['Total Pop Around Library']\n",
    "allRadiiPops['Prop 11 to 13 Min'] = allRadiiPops['Prop 11 to 13 Min']/allRadiiPops['Total Pop Around Library']\n",
    "allRadiiPops['Prop 13 to 15 Min'] = allRadiiPops['Prop 13 to 15 Min']/allRadiiPops['Total Pop Around Library']\n",
    "allRadiiPops['Prop 15 to 17 Min'] = allRadiiPops['Prop 15 to 17 Min']/allRadiiPops['Total Pop Around Library']\n",
    "allRadiiPops['Prop 17 to 19 Min'] = allRadiiPops['Prop 17 to 19 Min']/allRadiiPops['Total Pop Around Library']\n",
    "allRadiiPops['Prop 19 to 21 Min'] = allRadiiPops['Prop 19 to 21 Min']/allRadiiPops['Total Pop Around Library']\n",
    "allRadiiPops['Prop 21 to 23 Min'] = allRadiiPops['Prop 21 to 23 Min']/allRadiiPops['Total Pop Around Library']\n",
    "allRadiiPops['Prop 23 to 25 Min'] = allRadiiPops['Prop 23 to 25 Min']/allRadiiPops['Total Pop Around Library']\n",
    "allRadiiPops['Prop 25 to 27 Min'] = allRadiiPops['Prop 25 to 27 Min']/allRadiiPops['Total Pop Around Library']\n",
    "allRadiiPops['Prop 27 to 29 Min'] = allRadiiPops['Prop 27 to 29 Min']/allRadiiPops['Total Pop Around Library']\n",
    "allRadiiPops['Weighted Average Travel Time'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0fb0f4c-8b31-46a2-b094-220e2d82bbd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(len(allRadiiPops)):\n",
    "    allRadiiPops.loc[i,'Weighted Average Travel Time'] = (((allRadiiPops.loc[i,'Prop 0 to 5 Min'])*5) +\n",
    "                                                        ((allRadiiPops.loc[i,'Prop 5 to 7 Min'])*6) +\n",
    "                                                        ((allRadiiPops.loc[i,'Prop 7 to 9 Min'])*8) +\n",
    "                                                        ((allRadiiPops.loc[i,'Prop 9 to 11 Min'])*10) +\n",
    "                                                        ((allRadiiPops.loc[i,'Prop 11 to 13 Min'])*12) +\n",
    "                                                        ((allRadiiPops.loc[i,'Prop 13 to 15 Min'])*14) +\n",
    "                                                        ((allRadiiPops.loc[i,'Prop 15 to 17 Min'])*16) +\n",
    "                                                        ((allRadiiPops.loc[i,'Prop 17 to 19 Min'])*18) +\n",
    "                                                        ((allRadiiPops.loc[i,'Prop 19 to 21 Min'])*20) +\n",
    "                                                        ((allRadiiPops.loc[i,'Prop 21 to 23 Min'])*22) +\n",
    "                                                        ((allRadiiPops.loc[i,'Prop 23 to 25 Min'])*24) +\n",
    "                                                        ((allRadiiPops.loc[i,'Prop 25 to 27 Min'])*26) +\n",
    "                                                         (allRadiiPops.loc[i,'Prop 27 to 29 Min'])*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49552137-037b-46e3-842d-fb15aab07fca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "averageWalkingTimeNeighborhoods = pd.DataFrame(columns=['Branch', 'Average Walking Time (Minutes)'])\n",
    "averageWalkingTimeNeighborhoods['Branch'] = allRadiiPops['Branch']\n",
    "averageWalkingTimeNeighborhoods['Average Walking Time (Minutes)'] = allRadiiPops['Weighted Average Travel Time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1235d197-1b5b-4864-83bf-fcf1eb7c533a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "averageWalkingTimeNeighborhoods.to_csv('../CSV Compile for Library Info and Nbhs/TransportationCarTruckVanAverageWalkingNeighborhoods.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5334e4-fe82-447a-b328-fa251b4138cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
